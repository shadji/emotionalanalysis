<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Emotion Analysis Live Demo">
  <meta name="keywords" content="Emotional Analysis, BlazeFace, TFLite, Emotion Recognition, Machine Learning, TensorFlow, AI Demo">
  <meta name="author" content="Slav Hadjidimitrov">
  <meta property="og:title" content="Emotion Analysis Live Demo">
  <meta property="og:description" content="A live demo showcasing real-time emotion recognition based on facial analysis using BlazeFace and TensorFlow Lite.">
  <meta property="og:image" content="https://raw.githubusercontent.com/shadji/emotionalanalysis/main/assets/preview-image.jpg">
  <meta property="og:url" content="https://shadji.github.io/emotionalanalysis/">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Emotional Analysis Live Demo">
  <meta name="twitter:description" content="A live demo showcasing real-time emotion recognition based on facial analysis.">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/shadji/emotionalanalysis/main/assets/preview-image.jpg">

  <title>Emotion Recognition Demo with CNN</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      background-color: #f4f4f4;
    }
    .container {
      position: relative;
      width: 640px;
    }
    video {
      width: 100%;
      height: auto;
      border-radius: 8px;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    .emoji {
      position: absolute;
      top: 10px;
      left: 10px;
      width: 50px;
      height: 50px;
      z-index: 10;
    }
.bar-graph {
  display: flex;
  justify-content: space-between;
  width: 100%;
  max-width: 400px;
  height: 150px; /* Increased height to accommodate labels */
  margin-top: 20px;
  background-color: #eee;
  border-radius: 8px;
  padding: 5px;
}

.bar-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: flex-end;
  width: 20%;
}

.bar {
  width: 100%;
  background-color: #2196f3;
  border-radius: 4px;
  transition: height 0.3s ease;
}
/* Corresponding colors for each class */
#bar-0 { background-color: green; }  /* Happy */
#bar-1 { background-color: gray; }   /* Neutral */
#bar-2 { background-color: red; }    /* Sad */
#bar-3 { background-color: #FFA500; } /* Surprise */
label {
  margin-top: 5px;
  font-size: 14px;
  color: #333;
}
  </style>
</head>
<body>

  <div class="container">
    <!-- Webcam video stream -->
    <video id="video" autoplay playsinline></video>

    <!-- Canvas to draw bounding boxes -->
    <canvas id="overlay"></canvas>

    <!-- Emoji display -->
    <div id="emoji" class="emoji"></div>
  </div>
<div id="barGraph" class="bar-graph">
  <div class="bar-container">
    <div class="bar" id="bar-0" style="height: 0;"></div>
    <label for="bar-0">Happy</label>
  </div>
  <div class="bar-container">
    <div class="bar" id="bar-1" style="height: 0;"></div>
    <label for="bar-1">Neutral</label>
  </div>
  <div class="bar-container">
    <div class="bar" id="bar-2" style="height: 0;"></div>
    <label for="bar-2">Sad</label>
  </div>
  <div class="bar-container">
    <div class="bar" id="bar-3" style="height: 0;"></div>
    <label for="bar-3">Surprise</label>
  </div>
</div>
  <!-- TensorFlow.js and BlazeFace -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite@0.0.1-alpha.8/dist/tf-tflite.min.js"></script>

<script>
let blazefaceModel, emojiModel, video, canvas, ctx;

// Load the BlazeFace and Emoji predictor models
async function loadModels () {
  blazefaceModel = await blazeface.load(); // Load BlazeFace model
  emojiModel = await tflite.loadTFLiteModel('emoji_4.tflite'); // Load your emoji TFLite model
  console.log('Models loaded successfully.');
}

async function setupCamera () {
  video = document.getElementById('video');
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: 'user' } // front-facing camera
  });
  video.srcObject = stream;

  return new Promise((resolve) => {
    video.onloadedmetadata = () => {
      resolve(video);
    };
  });
}

// Detect faces and predict emojis
async function detectFaces () {
  const predictions = await blazefaceModel.estimateFaces(video, false);

  // Clear the canvas before drawing new bounding boxes
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  if (predictions.length > 0) {
    for (const prediction of predictions) {
      const [x, y] = prediction.topLeft;
      const [right, bottom] = prediction.bottomRight;
      const width = right - x;
      const height = bottom - y;

      // Draw bounding box
      ctx.beginPath();
      ctx.strokeStyle = 'red';
      ctx.lineWidth = 2;
      ctx.rect(x, y, width, height);
      ctx.stroke();

      // Extract and pass face region to emoji predictor
      await predictEmojiFromFace(x, y, width, height);
    }
  }

  window.requestAnimationFrame(detectFaces); // Continuously detect faces
}

// Preprocess face region and pass it to the emoji predictor
async function predictEmojiFromFace (x, y, width, height) {
  const faceCanvas = document.createElement('canvas');
  faceCanvas.width = 96; // Resize the face to 96x96 for the emoji predictor
  faceCanvas.height = 96;
  const faceCtx = faceCanvas.getContext('2d');

  // Draw the face region onto the canvas
  faceCtx.drawImage(video, x, y, width, height, 0, 0, 96, 96);

  // Extract image data and preprocess it
  const imageData = faceCtx.getImageData(0, 0, 96, 96);
  const imgArray = [];
  for (let i = 0; i < imageData.data.length; i += 4) {
    imgArray.push(imageData.data[i] / 255); // R channel normalized
    imgArray.push(imageData.data[i + 1] / 255); // G channel normalized
    imgArray.push(imageData.data[i + 2] / 255); // B channel normalized
  }

  // Convert to tensor
  const imgTensor = tf.tensor4d(imgArray, [1, 96, 96, 3]);

  // Predict emoji
  const prediction = await emojiModel.predict(imgTensor);
  // Update the bars with relative percentages
  const predictionData = prediction.dataSync(); // This will give probabilities for each class

  // Update the bars with relative percentages
  updateBarGraph(predictionData);
  const predictedClass = prediction.argMax(-1).dataSync()[0];

  // Display emoji based on prediction
  displayEmoji(predictedClass);
}
function updateBarGraph (predictionData) {
  for (let i = 0; i < 4; i++) {
    const bar = document.getElementById(`bar-${i}`);
    const percentage = predictionData[i] * 100; // Convert to percentage
    bar.style.height = `${percentage}%`;
  }
}
// Display emoji in the corner based on prediction
function displayEmoji (prediction) {
  const emojiElement = document.getElementById('emoji');
  emojiElement.innerHTML = ''; // Clear previous emoji

  if (prediction === 0) {
    emojiElement.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="12" cy="12" r="10" fill="green"/><path d="M15 10.5a1 1 0 100-2 1 1 0 000 2zm-6 0a1 1 0 100-2 1 1 0 000 2zm7 4a4 4 0 01-8 0h8z" fill="#000"/></svg>`;
  } else if (prediction === 1) {
    emojiElement.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="12" cy="12" r="10" fill="#C0C0C0"/><circle cx="9" cy="10" r="1"/><circle cx="15" cy="10" r="1"/><path d="M8 16h8v1H8z" fill="#000"/></svg>`;
  } else if (prediction === 2) {
    emojiElement.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="12" cy="12" r="10" fill="red"/><circle cx="9" cy="10" r="1" fill="#000"/><circle cx="15" cy="10" r="1" fill="#000"/><path d="M8 17c2-3 6-3 8 0" fill="none" stroke="#000" stroke-width="1.5" stroke-linecap="round"/></svg>`;
  } else if (prediction === 3) {
    emojiElement.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="12" cy="12" r="10" fill="#FFA500"/><circle cx="9" cy="10" r="1" fill="#000"/><circle cx="15" cy="10" r="1" fill="#000"/><circle cx="12" cy="16" r="2.5" fill="none" stroke="#000" stroke-width="1.5"/></svg>`;
  }
}

// Main function to set up camera and models
async function main () {
  await setupCamera();
  video.play();

  // Set up canvas overlay
  canvas = document.getElementById('overlay');
  ctx = canvas.getContext('2d');

  // Set the canvas dimensions to match the video
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  // Load models
  await loadModels();

  // Start detecting faces and predicting emojis
  detectFaces();
}

main(); // Run the application
</script>

<footer style="position: fixed; bottom: 0; width: 100%; text-align: center; font-size: small; background-color: #f8f8f8; padding: 10px 0; border-top: 1px solid #ddd;">
  <a href="https://github.com/shadji/emotionalanalysis" target="_blank" style="color: #333; text-decoration: none; font-weight: bold;" aria-label="View the project on GitHub">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="16px" height="16px" style="vertical-align: middle; margin-right: 5px;">
      <path d="M12 0.296C5.372 0.296 0 5.668 0 12.296c0 5.289 3.438 9.772 8.207 11.363.6.11.793-.26.793-.579v-2.23c-3.338.725-4.042-1.415-4.042-1.415-.546-1.387-1.333-1.756-1.333-1.756-1.089-.744.083-.729.083-.729 1.204.084 1.838 1.235 1.838 1.235 1.07 1.834 2.809 1.304 3.495.998.107-.775.42-1.304.762-1.603-2.665-.303-5.467-1.332-5.467-5.93 0-1.31.467-2.382 1.235-3.222-.123-.303-.535-1.524.118-3.176 0 0 1.008-.322 3.3 1.23.957-.266 1.982-.398 3.003-.404 1.02.006 2.046.138 3.005.404 2.289-1.552 3.295-1.23 3.295-1.23.655 1.652.243 2.873.12 3.176.77.84 1.235 1.912 1.235 3.222 0 4.61-2.807 5.624-5.48 5.921.431.372.815 1.102.815 2.221v3.293c0 .321.192.694.8.576C20.565 22.064 24 17.581 24 12.296c0-6.628-5.373-12-12-12z"/>
    </svg>
    View Project on GitHub
  </a>
</footer>
</body>
</html>
